# StereoDepthEstimation

## Set up the environment

```shell
conda env create -f environment.yaml
conda activate cv_env
```
This repository is used to train **PointPillars**  on point clouds generated by disparity images. The results of this project can be found in the folder **results**.

The 


## Training the PSMNET

To train **Pointpillars** on pointclouds generated by disparity images,  several repositories should be cloned and the file structure should look like this:

```
Main_folder/
├── StereoDepthEstimation/
├── PSMNET/
├── Pointpillars/
└── Kitti_dataset/
```
### PSMNET

Clone the [PSMNET GitHub](https://github.com/JiaRenChang/PSMNet) repository to the right folder. Then install the necessary libraries and generate the disparity images according to the instructions on the github repository. Place the generated disparity images in the Kitti_dataset folder. These images will be used to generate pointclouds in a later step.


### Pointpillars 

Clone the [Pointpillars](https://github.com/zhulf0804/PointPillars) repository to the right folder. Then install the necessary libraries.

### Generating Disparity pointclouds

Now everything is setup, the pointclouds can be generated from the disparity images. The following code generates pointclouds from the disparity images and transforms it to the lidarframe:
``` 
python3 disp_to_pc.py
```

### Preparing the data for pointpillars




